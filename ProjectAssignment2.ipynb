{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68141b5b-40b0-47d9-af83-3a8f8142af7a",
   "metadata": {},
   "source": [
    "# Project Assignment #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e31978-1453-42ff-a588-ef1f531662c0",
   "metadata": {},
   "source": [
    "## Step 2: Create a section in your notebook that introduces you (or your group) and introduces your project\n",
    "\n",
    "- If you (or your group) have made any changes to your research project idea or selected other/additional data, modify your project description accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aada7f7a-45c7-40a5-9762-904592cfb98b",
   "metadata": {},
   "source": [
    "This project was made by Crystal Huynh, Larry Qu, and Nelson Truong.\n",
    "\n",
    "### Research Question: What common speech patterns can be found in positive and negative commentary?\n",
    "Our group wanted to explore how people tend to speak when talking in an extremely positive and negative manner, especially in the context of movie reviews. Are there specific words that are frequently used when speaking in a positive sentiment versus a negative one? How often do those words show up in speech? How polarizing are these frequently used words? Do people tend to speak more when they are feeling positive or negative about something? This is the first step that we want to take when analyzing the speech patterns of movie reviews.\n",
    "\n",
    "### Why it Matters\n",
    "With this information, we can later see whether these patterns match typical human behavior/speech, or if they are more specific in an online, more anonymous environment. We can use our findings to potentially see how polarizing these spaces are and how they affect our society in the long run as this type of analysis can also be used on things like social media comments and news articles where commentary can be even more polarizing. As we explore speech patterns in settings outside of normal, in person conversation, we can get a better idea of how people truly think and feel in certain environments or how people will think and feel given what we already know.\n",
    "\n",
    "### Data Source\n",
    "[IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)\n",
    "[More Dataset Information](http://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "\n",
    "We are using the IMDB Dataset of 50K Movie Reviews Large Movie Review Dataset from kaggle which contains 50K movie reviews. This dataset can be used for binary sentiment classification as it contains highly polar movie reviews for training and testing.\n",
    "\n",
    "https://gist.github.com/mkulakowski2/4289441\n",
    "\n",
    "https://gist.github.com/mkulakowski2/4289437\n",
    "\n",
    "In order to indentify the positive and negative words, we can easily scan the web for premade datasets. These two shown above are datasets containing negative and positive words, respectively, that we can use to analyze our movie reviews with.\n",
    "\n",
    "### Project Scope\n",
    "The intended analysis is to see what are the common \"positive\" and \"negative\" words being used and how often they are used. The resulting visualizations for this would probably be something like a bar chart highlighting the ten most common \"positive\" and \"negative\" words and how often they appear in the dataset. We can also how long \"positive\" reviews are compared to \"negative\" reviews by checking the word count for each review and plotting the total word count frequency in a separate bar chart. Another analysis we could do is categorize common \"positive\" and \"negative\" words to see how polarizing they really are and plot this on another bar chart to visualize the scale of how positive \"positive\" reviews are and how negative \"negative\" reviews are.\n",
    "\n",
    "\n",
    "### Expected Insights\n",
    "We expect to see more polarizing \"positive\" and \"negative\" reviews to be lengthier in word count as people tend to speak more than they are feeling extremely \"positive\" or \"negative\" which is typical in normal, everyday, real life behavior. However, many people tend to not show their true thoughts and feelings when speaking in public, so perhaps in spaces like movie reviews, people's wording may be more polarizing than if they were to be giving the review in person. In other words, their online, anonymous reviews may be a lot more emotional and biased than what people would typically say aloud. We might see that although online commentary may reflect human behavior in that it represents what people actually are thinking and feeling, it may not be representative of what people would normally say to others. However, organizations can use these findings to gauge a more truthful reaction from the public for their respective initiatives and campaigns to see what they need to improve upon in order to generate a positive response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df9576-ba48-4d22-ac7f-9c384724dcd6",
   "metadata": {},
   "source": [
    "## Step 3: Create a section in your notebook that introduces your data\n",
    "\n",
    "- This can include summary information about the data, summary statistics where appropriate, and an identification of where there may be missing/incorrect/outlier data\n",
    "- It should include at least 4 exploratory data visualizations\n",
    "- This section does not need to be polished but it should be a good foundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d434714a-34b7-476f-8185-1465c37de462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7709e58-c6cf-48f1-a1bf-c7fe6e491c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df = pd.read_csv('IMDB Dataset.csv')\n",
    "imdb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c718a6-d453-4fce-b26c-2896c5682ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f388b22-c80f-43a4-825f-ff45d7675416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a05af-e2a5-484d-a39c-0b365b1f0422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 most common words in positive reviews\n",
      "br 97952\n",
      "'s 63002\n",
      "film 39754\n",
      "movie 35757\n",
      "'' 31962\n",
      "`` 31591\n",
      "n't 26471\n",
      "one 23831\n",
      "like 16414\n",
      "good 13759\n",
      "story 12042\n",
      "great 11790\n",
      "time 11453\n",
      "see 11437\n",
      "would 11098\n",
      "really 10443\n",
      "well 9931\n",
      "also 9373\n",
      "much 8747\n",
      "even 8331\n",
      "first 8278\n",
      "people 8154\n",
      "get 8023\n",
      "... 7898\n",
      "love 7747\n",
      "best 7536\n",
      "way 7413\n",
      "films 7230\n",
      "many 7084\n",
      "could 7056\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\n",
    "#most common words used for positive and negative sentiments\n",
    "#positiveReviews = []\n",
    "#negativeReviews = []\n",
    "positiveText = \"\"\n",
    "negativeText = \"\"\n",
    "\n",
    "\n",
    "for i in range(len(imdb_df['review'])):\n",
    "    if imdb_df['sentiment'][i] == \"positive\":\n",
    "        #positiveReviews.append(imdb_df['review'][i])\n",
    "        positiveText += imdb_df['review'][i]\n",
    "    else:\n",
    "        #negativeReviews.append(imdb_df['review'][i])\n",
    "        negativeText += imdb_df['review'][i]\n",
    "\n",
    "#print(positiveReviews[:5])\n",
    "\n",
    "#tokenize the words\n",
    "sent = sent_tokenize(positiveText)\n",
    "words = []\n",
    "for s in sent:\n",
    "    for w in word_tokenize(s):\n",
    "        words.append(w)\n",
    "        \n",
    "#remove stopwords\n",
    "myStopWords = list(punctuation) + stopwords.words('english')\n",
    "wordsNoStop = []\n",
    "for i in words:\n",
    "    if i.lower() not in myStopWords:\n",
    "        wordsNoStop.append(i)\n",
    "        \n",
    "print(\"30 most common words in positive reviews\")\n",
    "\n",
    "freq = FreqDist(wordsNoStop)\n",
    "for j in sorted(freq, key=freq.get, reverse=True)[:30]:\n",
    "    print(j,freq[j])\n",
    "    \n",
    "\n",
    "#tokenize the words\n",
    "sent = sent_tokenize(negativeText)\n",
    "words = []\n",
    "for s in sent:\n",
    "    for w in word_tokenize(s):\n",
    "        words.append(w)\n",
    "        \n",
    "#remove stopwords\n",
    "myStopWords = list(punctuation) + stopwords.words('english')\n",
    "wordsNoStop = []\n",
    "for i in words:\n",
    "    if i.lower() not in myStopWords:\n",
    "        wordsNoStop.append(i)\n",
    "        \n",
    "print(\"30 most common words in negative reviews\")\n",
    "\n",
    "negfreq = FreqDist(wordsNoStop)\n",
    "for j in sorted(negfreq, key=negfreq.get, reverse=True)[:30]:\n",
    "    print(j,negfreq[j])\n",
    "  \n",
    "#onlyPositive = []\n",
    "#for pword in freq:\n",
    "#    if pword not in negfreq:\n",
    "#        onlyPositive.append((pword, freq[pword]))\n",
    "        \n",
    "#onlyNegative = []\n",
    "#for negword in negfreq:\n",
    "#    if negword not in freq:\n",
    "#        onlyNegative.append((negword, freq[negword]))\n",
    "        \n",
    "#onlyPositive.sort(key = lambda x: -1*x[1]) \n",
    "#onlyNegative.sort(key = lambda x: -1*x[1]) \n",
    "\n",
    "    \n",
    "#print(\"30 most common words in positive reviews\")\n",
    "#print(onlyPositive[:30])\n",
    "\n",
    "#print(\"30 most common words in negative reviews\")\n",
    "#print(onlyNegative[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde5b02-2638-44f6-a3f1-903d5680873a",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "The following cells will be exploring a small subset of the dataset (first 1000 reviews, first 5000 reviews, etc) to try to gain an idea of what kind of dataset we are working with. Expanding upon the previous section where we looked at the 30 most frequent words in positive and negative reviews, we tried to create data visualizations to better represent these differences. Throughout our data exploration, we used a lot of tokenization and lemmatization to try to get the frequency of different words used in the movie reviews. This ended up in a lot of weird \"words\" such as br or '' which we all know aren't actually words. So, we tried to clean those words up where we could see them and then created the different bar charts of word frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845240c8-32bc-4fee-ad40-01fa712666a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdadf81-d29f-4990-932f-cc5e5d80e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile first 1000 reviews into one giant string\n",
    "reviews = \"\"\n",
    "for ind in range(1000):\n",
    "    reviews = reviews + \" \" + imdb_df[\"review\"][ind]\n",
    "    \n",
    "# Create a list of stop words\n",
    "stop_words = stopwords.words(\"english\") + list(punctuation)\n",
    "\n",
    "# Tokenize and convert all the reviews to lowercase\n",
    "words = word_tokenize(reviews.lower())\n",
    "\n",
    "# Remove all unwanted words\n",
    "completewords = [w for w in words if w not in stop_words]\n",
    "\n",
    "# Lemmatize the list of words\n",
    "completestemmed = [WordNetLemmatizer().lemmatize(w) for w in completewords]\n",
    "\n",
    "# Find the frequency of all words\n",
    "freq = FreqDist(completestemmed)\n",
    "\n",
    "# Turn this list into a pandas dataframe\n",
    "wordlist = []\n",
    "wordfreq = []\n",
    "for i in sorted(freq, key=freq.get, reverse=True):\n",
    "    wordlist.append(i)\n",
    "    wordfreq.append(freq[i])\n",
    "    \n",
    "df = pd.DataFrame({'wordlist':wordlist, 'wordfreq':wordfreq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc6828b-aab4-44f4-8d97-51791ea867dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c2d3a-c851-4d92-9bc2-07db757b36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purge weird words\n",
    "df = df.drop(labels=0)\n",
    "df = df.drop(labels=1)\n",
    "df = df.drop(labels=4)\n",
    "df = df.drop(labels=5)\n",
    "df = df.drop(labels=6)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8fb73-6179-4c2c-8b58-1d58edf88827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "df['wordfreq'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8632591f-ed70-44ba-a99f-14038c8d7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median\n",
    "df['wordfreq'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aef4bb-16d7-4a77-9d6d-9e1e51ba15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode\n",
    "df['wordfreq'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b7a0f-6e27-4f81-a4af-81ca3e0d9714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "df.plot.hist(bins=1000, xlim=(0, 150), ylim=(0,2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24b43f-3cd0-4246-9827-28af9155079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barchart of the 17 most frequent words\n",
    "bar_df = df.loc[0:20, [\"wordlist\", \"wordfreq\"]]\n",
    "bar_df.plot.barh(x=\"wordlist\", y=\"wordfreq\")\n",
    "#ax = bar_df.plot.bar(x='wordlist', y='wordfreq', rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57869b0f-8e22-4a61-80c9-3eaeafc1d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barchart of the 19 least frequent words\n",
    "bar_df = df.loc[18490:, [\"wordlist\", \"wordfreq\"]]\n",
    "bar_df.plot.barh(x=\"wordlist\", y=\"wordfreq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316328bf-5e29-4a60-a300-cd36a1a9d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look only at the first 1000 positive reviews\n",
    "reviews = \"\"\n",
    "for ind in range(5000):\n",
    "    if imdb_df[\"sentiment\"][ind] == \"positive\":\n",
    "        reviews = reviews + \" \" + imdb_df[\"review\"][ind]\n",
    "stop_words = stopwords.words(\"english\") + list(punctuation)\n",
    "words = word_tokenize(reviews.lower())\n",
    "completewords = [w for w in words if w not in stop_words]\n",
    "completestemmed = [WordNetLemmatizer().lemmatize(w) for w in completewords]\n",
    "freq = FreqDist(completestemmed)\n",
    "wordlist = []\n",
    "wordfreq = []\n",
    "for i in sorted(freq, key=freq.get, reverse=True):\n",
    "    wordlist.append(i)\n",
    "    wordfreq.append(freq[i])\n",
    "df = pd.DataFrame({'wordlist':wordlist, 'wordfreq':wordfreq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ea92a0-fce1-43c9-8147-40a1401c2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b75fa-886d-4f75-92b3-1124aa0efb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the dataframe and remove weird words\n",
    "df = df.drop(labels=0)\n",
    "df = df.drop(labels=1)\n",
    "df = df.drop(labels=4)\n",
    "df = df.drop(labels=5)\n",
    "df = df.drop(labels=7)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b8317-95fd-42a0-8f75-6365544a61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barchart\n",
    "bar_df = df.loc[0:50, [\"wordlist\", \"wordfreq\"]]\n",
    "bar_df.plot.barh(x=\"wordlist\", y=\"wordfreq\", figsize=(30,30), fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e9be2-7fd0-40db-81a7-ca647f990841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look only at the negative reviews\n",
    "reviews = \"\"\n",
    "for ind in range(5000):\n",
    "    if imdb_df[\"sentiment\"][ind] == \"negative\":\n",
    "        reviews = reviews + \" \" + imdb_df[\"review\"][ind]\n",
    "stop_words = stopwords.words(\"english\") + list(punctuation)\n",
    "words = word_tokenize(reviews.lower())\n",
    "completewords = [w for w in words if w not in stop_words]\n",
    "completestemmed = [WordNetLemmatizer().lemmatize(w) for w in completewords]\n",
    "freq = FreqDist(completestemmed)\n",
    "wordlist = []\n",
    "wordfreq = []\n",
    "for i in sorted(freq, key=freq.get, reverse=True):\n",
    "    wordlist.append(i)\n",
    "    wordfreq.append(freq[i])\n",
    "df = pd.DataFrame({'wordlist':wordlist, 'wordfreq':wordfreq})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b548378-fbdd-4066-9cac-e059aedad60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a27ce3c-5e1b-4f6f-952f-86989b51cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up dataframe and drop weird words\n",
    "df = df.drop(labels=0)\n",
    "df = df.drop(labels=1)\n",
    "df = df.drop(labels=4)\n",
    "df = df.drop(labels=5)\n",
    "df = df.drop(labels=6)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1263a1f-be60-44c4-8dfb-77a8c25ead83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barchart\n",
    "bar_df = df.loc[0:30, [\"wordlist\", \"wordfreq\"]]\n",
    "bar_df.plot.barh(x=\"wordlist\", y=\"wordfreq\", figsize=(30,30), fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83246b0b-d732-4335-bc5d-85f77939408d",
   "metadata": {},
   "source": [
    "We can see that in the reviews with negative sentiment, they are using very succinct words such as good or bad. This is probably due to the fact that the reviewer didn't like the movie so they don't want to waste time writing an indepth review about the movie. However, you look at the most frequent words for reviews with positive sentiment and you can see similar succint words. It turns out succinct words are just positive in general but the positive sentiment reviews includes more synonomous with good such as great or love."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf2caa-c2eb-4c72-a5df-1dc113b28769",
   "metadata": {},
   "source": [
    "## Step 4: Create a section in your notebook that includes the beginnings of your analysis\n",
    "\n",
    "- This should include code for data analysis\n",
    "- Include an additional 4 data visualizations of information directly relevant to your study topic\n",
    "    - Or describe 4 data visualizations that you want to make\n",
    "- This section does not need to be polished but it should be a good foundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93945c5b-d5c6-40b2-88c5-5d2470ddefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import vader\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288fed52-3ab1-4680-a9ec-27ed64945a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = vader.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9bc49b-a918-45a7-a5f2-946884a3a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing syntax stuffs\n",
    "\n",
    "#imdb_df.head(1)\n",
    "#imdb_df[\"review\"].iloc[0]\n",
    "#review1 = imdb_df[\"review\"].iloc[0]\n",
    "#sia.polarity_scores(review1)\n",
    "#sia.polarity_scores(review1)[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1d3a8-7918-4c1e-a6df-3f99a08d17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop for the whole dataset\n",
    "\n",
    "#k = 0\n",
    "#for index, row in imdb_df.iterrows():\n",
    "    #review = imdb_df[\"review\"].iloc[k]\n",
    "    #print('Review ' + str(k) + \"'s compound polarity score is \" + str(sia.polarity_scores(review)[\"compound\"]))\n",
    "    #k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee423df-173c-4a1f-b21e-b4956f85323a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = 0\n",
    "data = []\n",
    "for index, row in imdb_df.iterrows():\n",
    "    while k < 50:\n",
    "        review = imdb_df[\"review\"].iloc[k]\n",
    "        print('Review ' + str(k) + \"'s compound polarity score is \" + str(sia.polarity_scores(review)[\"compound\"]))\n",
    "        data.append(sia.polarity_scores(review)[\"compound\"])\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836518ea-9eb3-4745-8ba7-8cc45f267a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10585960-ab08-44a3-bf1f-02e096aa0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01ff9e-9d4d-455f-a7c2-e64160b7ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = imdb_df.groupby(imdb_df.sentiment)\n",
    "\n",
    "positive = grouped.get_group(\"positive\")\n",
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809bd4b-3f71-49e3-b749-75147a0a215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "posdata = []\n",
    "for index, row in positive.iterrows():\n",
    "    while k < 50:\n",
    "        review = positive[\"review\"].iloc[k]\n",
    "        print('Review ' + str(k) + \"'s compound polarity score is \" + str(sia.polarity_scores(review)[\"compound\"]))\n",
    "        posdata.append(sia.polarity_scores(review)[\"compound\"])\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f0c2c-7fe3-426b-819f-c6426431f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "posdata_df = pd.DataFrame(posdata)\n",
    "posdata_df.plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c1a7c-b535-4b97-a491-17669c13dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = imdb_df.groupby(imdb_df.sentiment)\n",
    "\n",
    "negative = grouped.get_group(\"negative\")\n",
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a67b8-19ed-4a96-b1f8-68cfba874ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "negdata = []\n",
    "for index, row in negative.iterrows():\n",
    "    while k < 50:\n",
    "        review = negative[\"review\"].iloc[k]\n",
    "        print('Review ' + str(k) + \"'s compound polarity score is \" + str(sia.polarity_scores(review)[\"compound\"]))\n",
    "        negdata.append(sia.polarity_scores(review)[\"compound\"])\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38408aa-ccca-4b36-aaf0-10f18849748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "negdata_df = pd.DataFrame(negdata)\n",
    "negdata_df.plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32f662-1303-4195-a183-c8910f8bbfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "posdata_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0071f9e-0067-452f-88f7-113dfdf6ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "negdata_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f86f59-454f-450e-9e32-13553101a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "n=1\n",
    "r = np.arange(n)\n",
    "width = 0.25\n",
    "\n",
    "x = [posdata_df.mean()[0], negdata_df.mean()[0]]\n",
    "\n",
    "ax1 = plt.subplot()\n",
    "ax1.set_xticks([1,2])\n",
    "\n",
    "# plt.bar(r, posdata_df.mean(), color = 'b',\n",
    "#         width = width, edgecolor = 'black',\n",
    "#         label='average positive sentiment')\n",
    "# plt.bar(r + width, negdata_df.mean(), color = 'r',\n",
    "#         width = width, edgecolor = 'black',\n",
    "#         label='average negative sentiment')\n",
    "plt.bar([1,2], x)\n",
    "\n",
    "ax1.set_xticklabels(['average positive sentiment', 'average negative sentiment'])\n",
    "plt.ylabel(\"Average Sentiment Value\")\n",
    "  \n",
    "plt.title(\"Average Sentiment Values\")  \n",
    "plt.text(1, 0.6, str(round(x[0], 3)))\n",
    "plt.text(2, 0.02, str(round(x[1], 3)))\n",
    "  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
